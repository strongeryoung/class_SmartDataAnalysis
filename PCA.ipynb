{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/strongeryoung/class_SmartDataAnalysis/blob/main/PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utO6fwR-QJAp",
        "outputId": "c8e82bf9-3323-4978-bb3c-3e7ed38380cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Stock_Investment_Strategy/Function')"
      ],
      "metadata": {
        "id": "8nT3gJJSRJDq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "f12cdeac-4e38-42a8-8efd-95d737bf7e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0163febe1fd4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Stock_Investment_Strategy/Function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Stock_Investment_Strategy/Function'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xmltodict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu4W0zc9RLWk",
        "outputId": "1761c883-471f-4647-c282-766383077cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "from datetime import date, timedelta, datetime\n",
        "from KEYS import *\n",
        "import pickle\n",
        "\n",
        "\n",
        "# coding: utf-8\n",
        "import requests \t  # API 요청할 때 쓰는 라이브러리\n",
        "import xmltodict \t  # xml형태를 dictionary {'a':1,'b':23}\n",
        "import json  # json을 쓰기위함\n",
        "import os\n",
        "import bs4\n",
        "\n",
        "from datetime import *\n",
        "from urllib.parse import urlencode, quote_plus, unquote\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import statsmodels\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy import stats\n",
        "\n",
        "from statsmodels.tsa.stattools import adfuller"
      ],
      "metadata": {
        "id": "i5DUVZRxRM_M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "f9186641-ebdc-400a-b2b4-995bdec35ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e85cd0a17a99>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# import matplotlib.pyplot as plt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mKEYS\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'KEYS'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import rcParams\n",
        "from matplotlib import font_manager, rc\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "# [출처] [파이썬] colab에서 plt 한글깨짐 해결|작성자 서울시립대 통계학과\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# 나눔글꼴 경로 설정\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
        "font_prop = fm.FontProperties(fname=font_path)\n",
        "\n",
        "plt.rcParams['font.family'] = font_prop.get_name()\n",
        "plt.rcParams['font.size'] = 12\n",
        "# [출처] [파이썬] colab에서 plt 한글깨짐 해결|작성자 서울시립대 통계학과"
      ],
      "metadata": {
        "id": "klFhStfVRPBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 정상화 테스트\n",
        "\n",
        "def stationarity_adf_test(Y_Data, col_name):\n",
        "    if len(col_name) == 0:\n",
        "        Stationarity_adf = pd.Series(sm.tsa.stattools.adfuller(Y_Data)[0:2],\n",
        "                                     index=['Statistics', 'p_value'])\n",
        "        for key, value in sm.tsa.stattools.adfuller(Y_Data)[4].items():\n",
        "            Stationarity_adf['Critical Value(%s)'%key] = value\n",
        "            Stationarity_adf['Maximum Information Criteria'] = sm.tsa.stattools.adfuller(Y_Data)[5]\n",
        "            Stationarity_adf = pd.DataFrame(Stationarity_adf, columns=['Stationarity_adf'])\n",
        "    else:\n",
        "        Stationarity_adf = pd.Series(sm.tsa.stattools.adfuller(Y_Data[col_name])[0:2],\n",
        "                                     index=['Statistics', 'p_value'])\n",
        "        for key, value in sm.tsa.stattools.adfuller(Y_Data[col_name])[4].items():\n",
        "            Stationarity_adf['Critical Value(%s)'%key] = value\n",
        "            Stationarity_adf['Maximum Information Criteria'] = sm.tsa.stattools.adfuller(Y_Data[col_name])[5]\n",
        "            Stationarity_adf = pd.DataFrame(Stationarity_adf, columns=['Stationarity_adf'])\n",
        "\n",
        "    return Stationarity_adf\n",
        "\n",
        "\n",
        "def get_time_series_for_bok(y, m, d, adj_days):\n",
        "\n",
        "    today = date.today()\n",
        "\n",
        "    # 경제 데이터 발표 주기를 고려한 날짜 조정 : 1개월 빼기\n",
        "    adj_dates = adj_days\n",
        "\n",
        "    time_adj = today - timedelta(days=adj_dates)\n",
        "    s_date = date(y, m, d)\n",
        "\n",
        "    # 텍스트화된 날자 데이터 만들기\n",
        "    date1 = s_date.strftime(\"%Y-%m-%d\").replace('-', '')\n",
        "    date2 = time_adj.strftime(\"%Y-%m-%d\").replace('-', '')\n",
        "\n",
        "    #date2 = str(date2)\n",
        "\n",
        "    # 시작 날짜와 끝 날짜를 datetime 형태로 변환\n",
        "    start_date = datetime.strptime(date1, \"%Y%m%d\")\n",
        "    end_date = datetime.strptime(date2, \"%Y%m%d\")\n",
        "\n",
        "    # date_range를 사용하여 time series 인덱스 생성\n",
        "    time_index = pd.date_range(start=start_date, end=end_date, freq='M')\n",
        "\n",
        "    n = len(time_index)\n",
        "\n",
        "    start_dt = date1[:-2]\n",
        "    end_dt = date2[:-2]\n",
        "\n",
        "    return start_dt, end_dt, time_index, n\n",
        "\n",
        "\n",
        "## 월간 경제 데이터 수신을 위한 API 함수 만들기\n",
        "\n",
        "def get_m_econ_data(n, item_code1, item_code2, item_code3, date1, date2, inter):\n",
        "\n",
        "    df_list = []\n",
        "\n",
        "    print(item_code1, item_code2)\n",
        "\n",
        "    key = KEYS['BOK']\n",
        "    url =  f\"http://ecos.bok.or.kr/api/StatisticSearch/{key}/json/kr/1/{n}/{item_code1}/{inter}/{date1}/{date2}/{item_code2}/{item_code3}\"\n",
        "    response = requests.get(url)\n",
        "    #print(response.status_code)\n",
        "    data = response.text\n",
        "    data = json.loads(data)\n",
        "    data_df = pd.DataFrame(data['StatisticSearch']['row'])\n",
        "    #print(data_df)\n",
        "    df_list.append(data_df)\n",
        "\n",
        "    return df_list\n",
        "\n",
        "\n",
        "def get_multi_econ_monthly_data(n, item_code1, item_code2, item_code3, s_date, e_date, inter):\n",
        "\n",
        "    df_list = []\n",
        "\n",
        "    date1 = s_date[:-2]\n",
        "    date2 = e_date[:-2]\n",
        "\n",
        "    for item in item_code2:\n",
        "\n",
        "        temp_df = get_m_econ_data(n, item_code1, item, item_code3, s_date, e_date, inter)\n",
        "        temp_df = temp_df[0]\n",
        "\n",
        "        temp_df['DATA_VALUE'] = temp_df['DATA_VALUE'].astype('float64')\n",
        "        temp_df['interval'] = 'M'\n",
        "        temp_df = temp_df[['TIME', 'ITEM_NAME1', 'DATA_VALUE', 'interval']].copy()\n",
        "\n",
        "        # 'TIME' 열을 날짜 형식으로 변환\n",
        "        temp_df['TIME'] = pd.to_datetime(temp_df['TIME'], format='%Y%m')\n",
        "        # 월말 기준으로 'TIME' 열을 변환\n",
        "        temp_df['TIME'] = temp_df['TIME'] + pd.offsets.MonthEnd(0)\n",
        "        temp_df = temp_df.set_index('TIME')\n",
        "        temp_df.index.name = 'Date'\n",
        "        df_list.append(temp_df)\n",
        "\n",
        "    df = pd.concat(df_list)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_bok_daily_data(n, item_code1, item_code2, s_date, e_date):\n",
        "\n",
        "    df_list = []\n",
        "\n",
        "    for item in item_code2:\n",
        "\n",
        "        temp_df = get_d_econ_data (n, item_code1, item, date1=s_date, date2=e_date)\n",
        "        temp_df = temp_df[0]\n",
        "        temp_df['DATA_VALUE'] = temp_df['DATA_VALUE'].astype('float64')\n",
        "        temp_df = temp_df[['TIME', 'ITEM_NAME1', 'DATA_VALUE']]\n",
        "        temp_df['interval'] = 'D'\n",
        "        stock_df = temp_df [['TIME', 'ITEM_NAME1', 'DATA_VALUE', 'interval']]\n",
        "        df_list.append(stock_df)\n",
        "\n",
        "    df = pd.concat(df_list)\n",
        "\n",
        "    return df\n",
        "\n",
        "def get_d_econ_data (n, item_code1, item_code2, date1, date2):\n",
        "\n",
        "    df_list = []\n",
        "\n",
        "    # print(item_code1, item_code2)\n",
        "\n",
        "    key =  KEYS['BOK']\n",
        "    url = f\"http://ecos.bok.or.kr/api/StatisticSearch/{key}/json/kr/1/{n}/{item_code1}/D/{date1}/{date2}/{item_code2}/\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "    #print(response.status_code)\n",
        "    data = response.text\n",
        "    data = json.loads(data)\n",
        "    #print(data)\n",
        "    data_df = pd.DataFrame(data['StatisticSearch']['row'])\n",
        "\n",
        "    df_list.append(data_df)\n",
        "    #df = pd.concat(df_list)\n",
        "    return df_list"
      ],
      "metadata": {
        "id": "Npv_H2O_RRPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Principal Component Analysis (PCA)란?\n",
        "\n",
        "주성분 분석(Principal Component Analysis, PCA)은 다차원 데이터의 차원을 줄이고 데이터의 주요한 구조를 보존하는데 사용되는 통계적인 방법입니다. 주로 데이터의 차원을 감소시키면서 정보 손실을 최소화하거나 데이터의 노이즈를 제거하기 위해 적용됩니다. PCA는 데이터를 새로운 좌표계로 변환하여 기존 데이터의 특성을 최대한 유지하면서 차원을 축소하는 방법으로 알려져 있습니다.\n",
        "\n",
        "PCA의 주요 단계는 다음과 같습니다:\n",
        "\n",
        "1. **데이터 중심화 (Centering):** 각 특성에서 평균을 빼서 데이터를 중심화합니다. 이렇게 하면 데이터의 중심이 원점에 위치하게 됩니다.\n",
        "\n",
        "2. **공분산 행렬 계산:** 중심화된 데이터의 공분산 행렬을 계산합니다. 공분산은 두 변수 간의 상관 관계를 나타내며 PCA는 데이터의 상관 관계를 이용하여 주성분을 찾습니다.\n",
        "\n",
        "3. **고유값과 고유벡터 계산:** 공분산 행렬의 고유값(eigenvalue)과 고유벡터(eigenvector)를 계산합니다. 고유값은 각 고유벡터에 대응되는 스칼라 값으로, 주성분의 중요도를 나타냅니다.\n",
        "\n",
        "4. **고유값 정렬:** 고유값을 크기순으로 정렬하고, 그에 따라 고유벡터도 정렬합니다. 이렇게 하면 가장 중요한 주성분부터 순서대로 선택할 수 있습니다.\n",
        "\n",
        "5. **주성분 선택:** 가장 큰 k개의 고유값과 그에 따른 고유벡터를 선택하여 새로운 좌표계를 구성합니다. 여기서 k는 새로운 차원의 수로, 사용자가 원하는 차원의 수를 의미합니다.\n",
        "\n",
        "6. **새로운 데이터 표현:** 선택된 주성분으로 원본 데이터를 새로운 좌표계로 변환합니다. 이로써 데이터의 차원이 감소하고, 주요한 정보가 유지되면서 노이즈나 불필요한 정보는 제거됩니다.\n",
        "\n",
        "PCA는 주로 데이터 압축, 시각화, 노이즈 제거, 특성 선택 등의 목적으로 사용되며, 다양한 분야에서 활발하게 적용되고 있습니다.\n",
        "\n"
      ],
      "metadata": {
        "id": "LWEO5Ez-UI9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PCA 사용 목적\n",
        "\n",
        "주성분 분석(Principal Component Analysis, PCA)는 다차원 데이터의 차원을 줄이고 주요한 정보를 보존하는 통계적 기법입니다. PCA의 목적은 원본 데이터의 특성을 최대한 유지하면서 새로운 좌표계로 데이터를 변환함으로써 차원을 축소하는 것입니다. 이는 다양한 상황에서 유용하게 활용될 수 있습니다.\n",
        "\n",
        "1. **차원 감소 (Dimensionality Reduction):** 다차원 데이터는 각 차원이 서로 상호작용하며 데이터의 복잡성을 높일 수 있습니다. PCA를 사용하여 데이터를 더 낮은 차원으로 표현하면 계산 효율성이 향상되며, 시각화 및 해석이 쉬워집니다.\n",
        "\n",
        "2. **데이터 시각화:** PCA는 데이터의 주요 구조를 보존하면서 차원을 감소시키므로, 데이터를 시각화하는 데 효과적입니다. 2차원 또는 3차원으로 축소된 데이터를 산점도 등으로 표현하여 데이터의 패턴이나 군집을 파악할 수 있습니다.\n",
        "\n",
        "3. **데이터 전처리:** PCA는 데이터에서 불필요한 노이즈나 상관성이 낮은 특성을 제거함으로써 데이터의 정제된 형태를 얻을 수 있습니다. 이는 모델의 성능을 향상시키고, 과적합을 방지하는 데 도움이 됩니다.\n",
        "\n",
        "4. **특성 선택:** PCA를 사용하면 주요한 정보를 가진 주성분들을 선택할 수 있습니다. 이를 통해 중요한 특성만을 고려하여 모델을 훈련시킬 수 있습니다.\n",
        "\n",
        "5. **상관 관계 분석:** PCA는 데이터의 공분산 구조를 이용하기 때문에 다양한 변수 간의 상관 관계를 분석하는 데 활용됩니다.\n",
        "\n",
        "6. **머신러닝에서의 성능 향상:** 차원 감소를 통해 모델의 계산 비용을 줄이고, 과적합을 방지하면서 모델의 일반화 성능을 향상시킬 수 있습니다.\n",
        "\n",
        "PCA는 특히 고차원의 데이터나 다중 공선성이 있는 데이터에서 효과적으로 사용됩니다. 그러나 주의할 점은 PCA가 데이터의 특성을 변환하므로 변환 후의 주성분이 원래 데이터에서 어떤 의미를 갖는지를 이해하는 것이 중요합니다."
      ],
      "metadata": {
        "id": "iYiiuBrsV_7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA 활용 단계\n",
        "\n",
        "1. 변수 수집\n",
        "2. 변수별 정상성 테스트\n",
        "3. 변수의 정상화\n",
        "4. 정규화 (표준화)\n",
        "5. PCA를 통해 산출된 변수의 변동성 설명력 확인\n",
        "6. 분석에 사용될 변수의 수 결정"
      ],
      "metadata": {
        "id": "RJHlRwFEWas9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 변수수집\n"
      ],
      "metadata": {
        "id": "w03MQ697XYa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 금리 스프레드 (Yield Spread)\n",
        "\n",
        "start_dt, end_dt, tm_index, n = get_time_series_for_bok(1990, 1, 1, 30)\n",
        "inter = 'M'\n",
        "\n",
        "item_code1 = '817Y002'\n",
        "item_code2 = ['010190000', '010195000', '010200000', '010200001', '010210000', '010300000', '010320000']\n",
        "                #get_multi_econ_monthly_data(n, item_code1, item_code2, s_date, e_date, inter)\n",
        "# bond_market_df = get_multi_econ_monthly_data(n, item_code1, item_code2, '', start_dt, end_dt, inter)\n",
        "\n",
        "today = date.today()\n",
        "past_date = date(1995, 1, 1)\n",
        "date1 = today.strftime(\"%Y-%m-%d\").replace('-', '')\n",
        "date2 = past_date.strftime(\"%Y-%m-%d\").replace('-', '')\n",
        "s_date = date2\n",
        "e_date = date1\n",
        "\n",
        "days_diff = today - past_date\n",
        "n = days_diff.days\n",
        "\n",
        "daily_interest_df = get_bok_daily_data(n, item_code1, item_code2, s_date, e_date)\n",
        "\n",
        "term_bond = daily_interest_df[(daily_interest_df['ITEM_NAME1'] == '국고채(10년)') | (daily_interest_df['ITEM_NAME1'] == '국고채(3년)')].copy()\n",
        "bond_pivot = term_bond.pivot(index='TIME', columns='ITEM_NAME1', values='DATA_VALUE').dropna()\n",
        "bond_pivot['term_spread'] = bond_pivot['국고채(10년)'] -  bond_pivot['국고채(3년)']\n",
        "term_spread = bond_pivot.copy()\n",
        "term_spread_re = term_spread.reset_index()\n",
        "term_spread_re['TIME'] = pd.to_datetime(term_spread_re['TIME'], format='%Y-%m-%d')\n",
        "term_spread_re"
      ],
      "metadata": {
        "id": "NUujNxX-ZT6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기업경기실사지수(전망)\n",
        "\n",
        "start_dt, end_dt, tm_index, n = get_time_series_for_bok(2003, 1, 1, 30)\n",
        "inter = 'M'\n",
        "\n",
        "item_code1 = '512Y008'\n",
        "item_code2 = ['BA']\n",
        "item_code3 = '99988'\n",
        "\n",
        "indus_pros = get_multi_econ_monthly_data(n, item_code1, item_code2, item_code3, start_dt, end_dt, inter)"
      ],
      "metadata": {
        "id": "sm7pIWg9ZT9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 종합주가지수\n",
        "\n",
        "item_code1 = '902Y002'\n",
        "item_code2 = ['3010101']\n",
        "item_code3 = ''\n",
        "\n",
        "kospi = get_multi_econ_monthly_data(n, item_code1, item_code2, item_code3, start_dt, end_dt, inter)"
      ],
      "metadata": {
        "id": "Z8jcLK1FZUAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 소비자동향조사\n",
        "\n",
        "item_code1 = '511Y002'\n",
        "item_code2 = ['FME']\n",
        "item_code3 = '99988'\n",
        "\n",
        "csi = get_multi_econ_monthly_data(n, item_code1, item_code2, item_code3, start_dt, end_dt, inter)"
      ],
      "metadata": {
        "id": "gs6DzExxZUFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 교역조건지수\n",
        "\n",
        "item_code1 = '403Y005'\n",
        "item_code2 = ['A']\n",
        "\n",
        "trade = get_multi_econ_monthly_data(n, item_code1, item_code2, item_code3, start_dt, end_dt, inter)"
      ],
      "metadata": {
        "id": "IdB-iscPZULG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 월말 대미환율\n",
        "\n",
        "item_code1 = '731Y004'\n",
        "item_code2 = ['0000001']\n",
        "item_code3 = '0000100'\n",
        "\n",
        "krw_dollar = get_multi_econ_monthly_data(n, item_code1, item_code2, item_code3, start_dt, end_dt, inter)"
      ],
      "metadata": {
        "id": "bA_uUIz6ZUN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 국내건설수주액\n",
        "\n",
        "item_code1 = '901Y020'\n",
        "item_code2 = ['I42A']\n",
        "item_code3 = ''\n",
        "\n",
        "construct1 = get_multi_econ_monthly_data(n, item_code1, item_code2, item_code3, start_dt, end_dt, inter)"
      ],
      "metadata": {
        "id": "He4pLqKXZUQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 주택매매가격지수\n",
        "\n",
        "item_code1 = '901Y093'\n",
        "item_code2 = ['H69A']\n",
        "item_code3 = 'R70A'\n",
        "\n",
        "h_price = get_multi_econ_monthly_data(n, item_code1, item_code2, item_code3, start_dt, end_dt, inter)"
      ],
      "metadata": {
        "id": "eSr5LEiaZUTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기계수주액\n",
        "\n",
        "item_code1 = '901Y018'\n",
        "item_code2 = ['I351']\n",
        "item_code3 = ''\n",
        "\n",
        "machine = get_multi_econ_monthly_data(n, item_code1, item_code2, item_code3, start_dt, end_dt, inter)"
      ],
      "metadata": {
        "id": "qD1zK70OZUWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 소매 판매액 지수\n",
        "\n",
        "item_code1 = '901Y100'\n",
        "item_code2 = ['G0']\n",
        "item_code3 = 'T3'\n",
        "\n",
        "consumer_spending = get_multi_econ_monthly_data(n, item_code1, item_code2, item_code3, start_dt, end_dt, inter)"
      ],
      "metadata": {
        "id": "Ps0yEZiFZUbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정상성 테스트"
      ],
      "metadata": {
        "id": "SWAoDOR-fDKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기업경기전망\n",
        "\n",
        "# raw_data = indus_pros[['DATA_VALUE']].copy()\n",
        "indus_pros['DATA_VALUE'] = indus_pros['DATA_VALUE'].astype('float64')\n",
        "\n",
        "# ADF 테스트 수행\n",
        "result = adfuller(indus_pros['DATA_VALUE'])\n",
        "\n",
        "# 결과 출력\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])\n",
        "print('Critical Values:', result[4])"
      ],
      "metadata": {
        "id": "bbRhzr89oRQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 종합주가지수\n",
        "\n",
        "kospi['DATA_VALUE'] = kospi['DATA_VALUE'].astype('float64')\n",
        "\n",
        "# ADF 테스트 수행\n",
        "result = adfuller(kospi['DATA_VALUE'])\n",
        "\n",
        "# 결과 출력\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])\n",
        "print('Critical Values:', result[4])"
      ],
      "metadata": {
        "id": "nq6z5HVifKrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 소비자동향조사\n",
        "\n",
        "csi['DATA_VALUE'] = csi['DATA_VALUE'].astype('float64')\n",
        "\n",
        "# ADF 테스트 수행\n",
        "result = adfuller(csi['DATA_VALUE'])\n",
        "\n",
        "# 결과 출력\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])\n",
        "print('Critical Values:', result[4])"
      ],
      "metadata": {
        "id": "nkApIgZRoRSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 교역조건지수\n",
        "\n",
        "trade['DATA_VALUE'] = trade['DATA_VALUE'].astype('float64')\n",
        "\n",
        "# ADF 테스트 수행\n",
        "result = adfuller(trade['DATA_VALUE'])\n",
        "\n",
        "# 결과 출력\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])\n",
        "print('Critical Values:', result[4])"
      ],
      "metadata": {
        "id": "gvSmka7MoRVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원달러 환율\n",
        "\n",
        "krw_dollar['DATA_VALUE'] = krw_dollar['DATA_VALUE'].astype('float64')\n",
        "\n",
        "# ADF 테스트 수행\n",
        "result = adfuller(krw_dollar['DATA_VALUE'])\n",
        "\n",
        "# 결과 출력\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])\n",
        "print('Critical Values:', result[4])"
      ],
      "metadata": {
        "id": "PSMFgfQsgt6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 국내건설수주액\n",
        "\n",
        "construct1['DATA_VALUE'] = construct1['DATA_VALUE'].astype('float64')\n",
        "\n",
        "# ADF 테스트 수행\n",
        "result = adfuller(construct1['DATA_VALUE'])\n",
        "\n",
        "# 결과 출력\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])\n",
        "print('Critical Values:', result[4])"
      ],
      "metadata": {
        "id": "sBM9TzcVgt9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 주택매매가격지수\n",
        "\n",
        "h_price['DATA_VALUE'] = h_price['DATA_VALUE'].astype('float64')\n",
        "\n",
        "# ADF 테스트 수행\n",
        "result = adfuller(h_price['DATA_VALUE'])\n",
        "\n",
        "# 결과 출력\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])\n",
        "print('Critical Values:', result[4])"
      ],
      "metadata": {
        "id": "oV5TcpQZguAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기계 수주액\n",
        "\n",
        "machine['DATA_VALUE'] = machine['DATA_VALUE'].astype('float64')\n",
        "\n",
        "# ADF 테스트 수행\n",
        "result = adfuller(machine['DATA_VALUE'])\n",
        "\n",
        "# 결과 출력\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])\n",
        "print('Critical Values:', result[4])"
      ],
      "metadata": {
        "id": "_FFc1dKqguCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 소매판매액 지수\n",
        "\n",
        "consumer_spending['DATA_VALUE'] = consumer_spending ['DATA_VALUE'].astype('float64')\n",
        "\n",
        "# ADF 테스트 수행\n",
        "result = adfuller(consumer_spending['DATA_VALUE'])\n",
        "\n",
        "# 결과 출력\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])\n",
        "print('Critical Values:', result[4])"
      ],
      "metadata": {
        "id": "WVAHju4mguFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 정상성 데이터 그룹 : 소비자동향조사, 기계수주액\n",
        "\n",
        "- 비정상성 데이터 그룹 : 기업경기전망, 종합주가지수, 교역조건지수, 원달러환율, 국내건설수주액, 주택매매가격지수, 소매판매액지수"
      ],
      "metadata": {
        "id": "tkyx7c1uj_lK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 정상화 작업"
      ],
      "metadata": {
        "id": "i5KOzJ_AmUr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indus_pros['indus_prospect_diff'] = indus_pros['DATA_VALUE'].pct_change(12)\n",
        "kospi['kospi_diff'] = kospi['DATA_VALUE'].pct_change()\n",
        "trade['trade_diff'] = trade['DATA_VALUE'].pct_change()\n",
        "krw_dollar['fx_diff'] = krw_dollar['DATA_VALUE'].pct_change()\n",
        "construct1['construct_diff'] = construct1['DATA_VALUE'].pct_change()\n",
        "h_price['house_price'] = h_price['DATA_VALUE'].pct_change()\n",
        "consumer_spending['house_price_diff'] = consumer_spending['DATA_VALUE'].pct_change()"
      ],
      "metadata": {
        "id": "AMqaexXdguIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csi['csi'] = csi['DATA_VALUE'].copy()"
      ],
      "metadata": {
        "id": "HHFciVLhguK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "machine['machine_order'] = machine['DATA_VALUE'].copy()"
      ],
      "metadata": {
        "id": "U5U26StgguNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "macro_df = pd.concat([indus_pros['indus_prospect_diff'], kospi['kospi_diff'], trade['trade_diff'],\n",
        "                      krw_dollar['fx_diff'], construct1['construct_diff'], h_price['house_price'],\n",
        "                      consumer_spending['house_price_diff'], csi['csi'], machine['machine_order'],\n",
        "                      ], axis=1)"
      ],
      "metadata": {
        "id": "XMnUEdZaguQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "macro_df = macro_df.dropna()"
      ],
      "metadata": {
        "id": "vsip5S5vguUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "macro_df.index"
      ],
      "metadata": {
        "id": "puKcaMQgxfat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_List = macro_df.columns.tolist()\n",
        "\n",
        "for col in col_List:\n",
        "\n",
        "    # ADF 테스트 수행\n",
        "    result = adfuller(macro_df[col])\n",
        "\n",
        "    # 결과 출력\n",
        "    print('ADF Statistic:', result[0])\n",
        "    print('p-value:', result[1])\n",
        "    print('Critical Values:', result[4])"
      ],
      "metadata": {
        "id": "7xJtYeCEguaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_dt, end_dt, tm_index, n = get_time_series_for_bok(1990, 1, 1, 30)\n",
        "inter = 'M'\n",
        "\n",
        "item_code1 = '301Y013'\n",
        "item_code2 = ['2C1Y00', '2C2Y00']\n",
        "item_code3 = ''\n",
        "\n",
        "data = get_multi_econ_monthly_data(n, item_code1, item_code2, item_code3, start_dt, end_dt, inter)\n",
        "data"
      ],
      "metadata": {
        "id": "Y_06ZiTSRYYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hhn2GTvItH97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PCA를 위한 데이터 정규화"
      ],
      "metadata": {
        "id": "ph74oIR0tdOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##  library import\n",
        "from sklearn import preprocessing\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "OiICcGRNtIC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "std_scaler = preprocessing.StandardScaler().fit(macro_df)\n",
        "scaled_macro = std_scaler.transform(macro_df)\n",
        "scaled_macro_df = pd.DataFrame(scaled_macro, columns=macro_df.columns)"
      ],
      "metadata": {
        "id": "C3g-ALfptIF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_macro_df"
      ],
      "metadata": {
        "id": "NhHYcuqptIIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_macro_df.describe()"
      ],
      "metadata": {
        "id": "BKC1xKpWZVzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-bywBllvZ1q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 변수 총위험 설명력과 분석에 사용될 PCA 요인 결정"
      ],
      "metadata": {
        "id": "UzlAM6GlZ2J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(random_state=1107)\n",
        "X_p = pca.fit_transform(scaled_macro_df)\n",
        "\n",
        "variance_df = pd.Series(np.cumsum(pca.explained_variance_ratio_))\n",
        "variance_df"
      ],
      "metadata": {
        "id": "Nb1_za07tILS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 4\n",
        "pca = PCA(n_components=n)\n",
        "macro_pca_df = pca.fit_transform(scaled_macro_df)\n",
        "pca_col_name = ['macro_pca1', 'macro_pca2', 'macro_pca3', 'macro_pca4']\n",
        "macro_pca_df = pd.DataFrame(macro_pca_df, columns=pca_col_name)"
      ],
      "metadata": {
        "id": "eumlb_rstIOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "macro_pca_df['date'] = macro_df.index\n",
        "macro_pca_df.head(5)\n",
        "external_vars = macro_pca_df.set_index('date')\n",
        "\n",
        "external_vars_re = external_vars.loc['2010-09-30': '2023-09-30']\n",
        "external_vars_re"
      ],
      "metadata": {
        "id": "vXoBI4CItIQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 분석 적용 사례"
      ],
      "metadata": {
        "id": "lKVxXWKdaBtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_dt, end_dt, tm_index, n = get_time_series_for_bok(1990, 1, 1, 30)\n",
        "inter = 'M'\n",
        "\n",
        "item_code1 = '301Y013'\n",
        "item_code2 = ['2C1Y00', '2C2Y00']\n",
        "item_code3 = ''\n",
        "\n",
        "data = get_multi_econ_monthly_data(n, item_code1, item_code2, item_code3, start_dt, end_dt, inter)\n",
        "\n",
        "data.columns= ['항목', '여행수지', '주기']\n",
        "\n",
        "data_re = data.reset_index()\n",
        "\n",
        "pivot_data = data_re.pivot(index='Date', columns='항목', values='여행수지')\n",
        "\n",
        "# pivot_data['일반여행수입'].plot()"
      ],
      "metadata": {
        "id": "TU_JMpA9tIn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_data[['여행수입_log', '여행지급_log']] = np.log(pivot_data[['일반여행수입', '일반여행지급']])"
      ],
      "metadata": {
        "id": "mHdj40AXP-yH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_data_re = pivot_data.loc['2010-09-30':]\n",
        "pivot_data_re"
      ],
      "metadata": {
        "id": "lio5aLwuVG4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "tourism_balance_log = pivot_data_re[['여행수입_log', '여행지급_log']]\n",
        "target_df = tourism_balance_log[['여행수입_log']].copy()\n",
        "\n",
        "Y_train = target_df.iloc[:-1]\n",
        "\n",
        "## Parameter Setting\n",
        "p, q = range(0,2), range(0,2)\n",
        "d = range(1,2)\n",
        "P, Q = range(0,2), range(0,2)\n",
        "D = range(0,2)\n",
        "m = 12\n",
        "trend_pdq = list(product(p, d, q))\n",
        "seasonal_pdq = [(candi[0], candi[1], candi[2], m) for candi in list(product(P, D, Q))]\n",
        "\n",
        "## SARIMAX\n",
        "AIC = []\n",
        "SARIMAX_order = []\n",
        "for trend_param in tqdm(trend_pdq):\n",
        "    for seasonal_params in seasonal_pdq:\n",
        "        try:\n",
        "            result =sm.tsa.SARIMAX(Y_train, trend='c',\n",
        "                                   order=trend_param, seasonal_order=seasonal_params, exog=external_vars_re).fit()\n",
        "            print('Fit SARIMAX: trend_order={} seasonal_order={} AIC={}, BIC={}'.format(trend_param, seasonal_params, result.aic, result.bic, end='\\r'))\n",
        "            AIC.append(result.aic)\n",
        "            SARIMAX_order.append([trend_param, seasonal_params])\n",
        "        except:\n",
        "            continue\n",
        "## Parameter Selection\n",
        "print('The smallest AIC is {} for model SARIMAX{}x{}'.format(min(AIC), SARIMAX_order[AIC.index(min(AIC))][0], SARIMAX_order[AIC.index(min(AIC))][1]))"
      ],
      "metadata": {
        "id": "sr5hgK9LtIt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 리스트를 데이터프레임으로 변환\n",
        "order_df = pd.DataFrame(SARIMAX_order, columns=['(p, d, q)', '(P, D, Q, M)'])\n",
        "# (p, d, q) 컬럼을 나누어 각각의 컬럼으로 만들기\n",
        "order_df[['p', 'd', 'q']] = pd.DataFrame(order_df['(p, d, q)'].tolist(), index=order_df.index)\n",
        "order_df[['P', 'D', 'Q', 'M']] = pd.DataFrame(order_df['(P, D, Q, M)'].tolist(), index=order_df.index)\n",
        "\n",
        "# 불필요한 열 제거\n",
        "order_df = order_df.drop(['(p, d, q)', '(P, D, Q, M)'], axis=1)\n",
        "order_df.head(5)\n",
        "\n",
        "AIC_df = pd.DataFrame(AIC, columns= ['AIC'])\n",
        "\n",
        "Sarima_AIC = pd.concat([order_df, AIC_df], axis=1).sort_values(by='AIC', ascending=True)\n",
        "Sarima_AIC.head(3)"
      ],
      "metadata": {
        "id": "dUjLcR5Ovg5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seasonal_order = 12\n",
        "\n",
        "step = 12\n",
        "\n",
        "## SARIMAX\n",
        "logarithm, differencing = True, False\n",
        "\n",
        "fit_ts_sarimax = sm.tsa.SARIMAX(Y_train, order=(0,1,0), seasonal_order=(1,0,1,seasonal_order), trend='c', exog=external_vars_re).fit()\n",
        "display(fit_ts_sarimax.summary())"
      ],
      "metadata": {
        "id": "sfj7ZB9Ivg8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "주어진 결과로부터 다양한 통계적 특성을 확인할 수 있습니다. 주로 자기상관, 잔차의 정규성, 이분산성, 그리고 잔차의 자기회귀 여부 등을 확인하는 지표들이 포함되어 있습니다.\n",
        "\n",
        "자기상관 (Autocorrelation):\n",
        "\n",
        "Ljung-Box (L1) (Q): 0.48\n",
        "Prob(Q): 0.49\n",
        "Ljung-Box 통계량은 시계열 데이터에서 자기상관을 검정하는 통계량입니다. 여기서 Q 값이 낮으면 자기상관이 존재하지 않는 것으로 해석할 수 있습니다. Prob(Q)는 Q 값에 대한 p-value를 의미하며, 보통 0.05보다 작을 때 자기상관이 존재한다고 판단합니다. 이 경우에는 Prob(Q)가 0.49로 높으므로 자기상관이 존재하지 않는 것으로 해석할 수 있습니다.\n",
        "\n",
        "잔차의 정규분포:\n",
        "\n",
        "Jarque-Bera (JB): 14.79\n",
        "Prob(JB): 0.00\n",
        "Jarque-Bera 검정은 잔차의 정규성을 평가하는 테스트입니다. Prob(JB)는 검정 통계량에 대한 p-value를 나타냅니다. 여기서는 Prob(JB)가 0.00으로 매우 낮으므로, 잔차가 정규분포를 따르지 않는 것으로 해석할 수 있습니다.\n",
        "\n",
        "이분산성 (Heteroskedasticity):\n",
        "\n",
        "Heteroskedasticity (H): 1.46\n",
        "Prob(H) (two-sided): 0.18\n",
        "Heteroskedasticity 검정은 잔차의 분산이 일정하지 않은지를 확인합니다. Prob(H)가 0.18로 상당히 높기 때문에, 이분산성이 존재하지 않는 것으로 판단할 수 있습니다."
      ],
      "metadata": {
        "id": "odSybDFH5ERz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gE78N-NN4S_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터에 대한 예측\n",
        "# predictions = fit_ts_sarimax.predict()\n",
        "# predictions = predictions.iloc[1:]\n",
        "\n",
        "# # 잔차 추출\n",
        "# residuals = fit_ts_sarimax.resid\n",
        "# residuals = residuals.iloc[1:]\n",
        "# # Scatter plot 그리기\n",
        "# plt.scatter(predictions, residuals,)\n",
        "# plt.title('Residuals vs Predictions')\n",
        "# plt.xlabel('Predictions')\n",
        "# plt.ylabel('Residualss')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "Vt66fZDWvg_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nm-_gqj_vhJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 글로벌 경기선행지수 수집"
      ],
      "metadata": {
        "id": "rp_j14n5eedO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Composite Leading Indicator\n",
        "# https://data.oecd.org/leadind/composite-leading-indicator-cli.htm\n",
        "def getCLI(country):\n",
        "    uri = 'https://stats.oecd.org/sdmx-json/data/DP_LIVE/' + country + '.CLI.AMPLITUD.LTRENDIDX.M/OECD?json-lang=en&dimensionAtObservation=allDimensions&startPeriod=2000-01&endPeriod=2023-10'\n",
        "    resp = requests.get(uri)\n",
        "    result = json.loads(resp.text)\n",
        "\n",
        "    dates = []\n",
        "    cli = []\n",
        "    cli_code = 'CLI.' + country\n",
        "\n",
        "    observations = result['dataSets'][0]['observations']\n",
        "    for key in observations:\n",
        "        obs = observations[key][0]\n",
        "        cli.append(obs)\n",
        "\n",
        "    time_period = result['structure']['dimensions']['observation'][5]['values']\n",
        "    for date in time_period:\n",
        "        date = date['id']\n",
        "        year = int(date[:4])\n",
        "        month = int(date[5:7])\n",
        "        dates.append(datetime(year=year, month=month, day=1))\n",
        "\n",
        "    df = pd.DataFrame(data=cli, index=dates, columns=[cli_code])\n",
        "    return df"
      ],
      "metadata": {
        "id": "s-cVLHfsXHxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "country_code = 'KOR'\n",
        "\n",
        "cli_code = 'CLI.' + country_code\n",
        "\n",
        "cli = getCLI(country_code)"
      ],
      "metadata": {
        "id": "4FB6XVbmXIr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cli"
      ],
      "metadata": {
        "id": "4K4oehaTYCip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VP-qkpoc3l67"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}